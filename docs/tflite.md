---
title: TFLite brings ML inference to constrained devices
status: seedling
created: 2026-01-25
---

TensorFlow Liteâ€”a runtime for deploying trained models on mobile and embedded hardware. Smaller binaries, quantized weights, optimized kernels.

The workflow: train full-size model, convert to TFLite format, run inference on-device. No network round-trip, no cloud dependency, no latency.

Enables applications like [[gesture-recognition]] on microcontrollers, where real-time response matters and connectivity can't be assumed.

See also: [[simcap]]
